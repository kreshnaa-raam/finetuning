{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "\n",
    "ds = load_dataset(\"Kaludi/Customer-Support-Responses\")\n",
    "\n",
    "# splitting data into train and test\n",
    "split_dataset = ds['train'].train_test_split(test_size=24, shuffle=False)\n",
    "split_dataset['train'] = split_dataset['train']\n",
    "split_dataset['eval'] = split_dataset['test']\n",
    "del split_dataset['test']\n",
    "\n",
    "# DatasetDict with the splits\n",
    "new_dataset = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'eval': split_dataset['eval']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to chat completion. This is needed to finetune models like GPT3.5+\n",
    "def convert_to_chat_completion(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You're a Customer Support Bot\"},\n",
    "            {\"role\": \"user\", \"content\": row['query']},\n",
    "            {\"role\": \"assistant\", \"content\": row['response']}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Save the converted text to jsonl file\n",
    "def save_as_jsonl(dataset, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for row in dataset:\n",
    "            formatted_row = convert_to_chat_completion(row)\n",
    "            f.write(json.dumps(formatted_row) + '\\n')\n",
    "\n",
    "# Convert and save the datasets as train and eval\n",
    "save_as_jsonl(new_dataset['train'], 'train.jsonl')\n",
    "save_as_jsonl(new_dataset['eval'], 'eval.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load open ai environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Connect to openai client\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload train file\n",
    "client.files.create(\n",
    "  file=open(\"train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload test file\n",
    "client.files.create(\n",
    "  file=open(\"eval.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup finetuning with hyperparamete\n",
    "train_file_id = \"file-RN2COkigFkNUZIRmnPVsbJHd\"\n",
    "eval_file_id = \"file-rEzAq1vatTRAA2XnMmGKyQul\"\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=train_file_id,  \n",
    "  validation_file=eval_file_id,\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  hyperparameters={\n",
    "    \"batch_size\": 4,\n",
    "    \"learning_rate_multiplier\": 0.1,\n",
    "    \"n_epochs\": 50\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store finetuned model \n",
    "ft_model = client.fine_tuning.jobs.retrieve(\"ftjob-UuEgkubgXVNJDjmL494oIXDr\").fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eval library ragas to test model performance\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness,answer_relevancy,answer_correctness,answer_similarity\n",
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "import os\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_correctness\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "ft_model_ = ChatOpenAI(model_name=ft_model)\n",
    "\n",
    "\n",
    "# Transform dataset to include required columns\n",
    "eval_dataset = [\n",
    "    {\n",
    "        'contexts': '', \n",
    "        'question': item['query'],\n",
    "        'answer': item['response'],\n",
    "        'ground_truth': item['response'],\n",
    "    }\n",
    "    for item in new_dataset['eval']\n",
    "]\n",
    "eval_df = pd.DataFrame(eval_dataset)\n",
    "\n",
    "# Create the required format of dataset.dict to pass to the ragas eval function\n",
    "eval_dataset_2 = {\n",
    "    'question': eval_df['question'].tolist(),\n",
    "    'answer': eval_df['answer'].tolist(),\n",
    "    'contexts': eval_df['contexts'].apply(lambda x: [x] if isinstance(x, str) else x).tolist(),  # Ensure contexts is a list of lists\n",
    "    'ground_truth': eval_df['ground_truth'].tolist()\n",
    "}\n",
    "eval_dataset_3 = Dataset.from_dict(eval_dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate using ragas for faithfulness, answer_relevancy and answer_correctness\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "result = evaluate(\n",
    "    eval_dataset_3,\n",
    "    metrics=[faithfulness,answer_relevancy,answer_correctness],\n",
    "    llm=ft_model_ \n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft-pesto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
